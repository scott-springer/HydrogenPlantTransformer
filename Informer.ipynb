{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMnoRaOKJpPUQMNUVnEh8dV"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"v4aHfwYPw_nf","executionInfo":{"status":"ok","timestamp":1670824362200,"user_tz":420,"elapsed":21775,"user":{"displayName":"Jiwei Yao","userId":"13030184443101343713"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"4a6828ae-1192-4686-b532-33d30a2a9ab7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import math\n","import torch\n","import scipy.io\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import os"],"metadata":{"id":"UXvroJuf1EVR","executionInfo":{"status":"ok","timestamp":1670824365922,"user_tz":420,"elapsed":3726,"user":{"displayName":"Jiwei Yao","userId":"13030184443101343713"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["data = scipy.io.loadmat('/content/drive/MyDrive/Deep Learning/Deep Learning Project/big_data_cont.mat')\n","df = pd.DataFrame(data['big_data'], columns = ['T_Cin','T_Ain','m_Ain', 'm_Cin', 'c_H2in', 'j_avg', 'T_out', 'conv', 'U'])\n","df = df.iloc[::6, :]\n","\n","\n","# Add time stamp, 0: last time at previous SS\n","\n","def find_true_false(array):\n","  pre = False\n","  res_index = []\n","  for i in range(1, len(array)):\n","    if array[i-1] and array[i] == False:\n","      res_index.append(i-1)\n","  return res_index\n","\n","df[\"Time_Stamp\"] = 0\n","test_array = np.abs(np.diff(df[\"T_Cin\"])) < 5e-2\n","index = find_true_false(test_array)\n","begin_index = 0\n","for i in range(len(index)):\n","  end_index = index[i]+1\n","  df.iloc[begin_index:end_index, -1] = np.arange(0, end_index-begin_index)\n","  begin_index = end_index"],"metadata":{"id":"KZu8T_an05LA","executionInfo":{"status":"ok","timestamp":1670824375458,"user_tz":420,"elapsed":9547,"user":{"displayName":"Jiwei Yao","userId":"13030184443101343713"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","class StandardScaler():\n","    def __init__(self):\n","        self.mean = 0.\n","        self.std = 1.\n","    \n","    def fit(self, data):\n","        self.mean = data.mean(0)\n","        self.std = data.std(0)\n","\n","    def transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        return (data - mean) / std\n","\n","    def inverse_transform(self, data):\n","        mean = torch.from_numpy(self.mean).type_as(data).to(data.device) if torch.is_tensor(data) else self.mean\n","        std = torch.from_numpy(self.std).type_as(data).to(data.device) if torch.is_tensor(data) else self.std\n","        if data.shape[-1] != mean.shape[-1]:\n","            mean = mean[-1:]\n","            std = std[-1:]\n","        return (data * std) + mean\n","\n","class Dataset_cont_min(Dataset):\n","    def __init__(self, dataframe, flag='train', size=None, \n","                 features='M', target='conv', scale=True, inverse=False, timeenc=0, cols=None):\n","        # size [seq_len, label_len, pred_len]\n","        # info\n","        if size == None:\n","            self.seq_len = 150*4*4\n","            self.label_len = 150*4\n","            self.pred_len = 150*4\n","        else:\n","            self.seq_len = size[0]\n","            self.label_len = size[1]\n","            self.pred_len = size[2]\n","        # init\n","        assert flag in ['train', 'test', 'val']\n","        type_map = {'train':0, 'val':1, 'test':2}\n","        self.set_type = type_map[flag]\n","        \n","        self.features = features\n","        self.target = target\n","        self.scale = scale\n","        self.inverse = inverse\n","        self.timeenc = timeenc\n","        self.dataset = dataframe\n","\n","        self.__read_data__()\n","\n","    def __read_data__(self):\n","        self.scaler = StandardScaler()\n","        df_raw = self.dataset\n","\n","        train_end = 263788 #included\n","        val_end = 351687   #included\n","        test_end = 439978  #included\n","\n","        border1s = [0,  train_end+1 - self.seq_len, val_end+1 - self.seq_len]\n","        border2s = [train_end+1, val_end+1, test_end+1]\n","        border1 = border1s[self.set_type]\n","        border2 = border2s[self.set_type]\n","        \n","        if self.features=='M' or self.features=='MS':\n","            cols_data = df.columns[:-1]\n","            df_data = df_raw[cols_data]\n","        elif self.features=='S':\n","            df_data = df_raw[[self.target]]\n","\n","        if self.scale:\n","            train_data = df_data[border1s[0]:border2s[0]]\n","            self.scaler.fit(train_data.values)\n","            data = self.scaler.transform(df_data.values)\n","        else:\n","            data = df_data.values\n","            \n","        df_stamp = df_raw[['Time_Stamp']][border1:border2].values\n","        data_stamp = df_stamp\n","\n","        self.data_x = data[border1:border2]\n","        if self.inverse:\n","            self.data_y = df_data.values[border1:border2]\n","        else:\n","            self.data_y = data[border1:border2]\n","        self.data_stamp = data_stamp\n","    \n","    def __getitem__(self, index):\n","        s_begin = index\n","        s_end = s_begin + self.seq_len\n","        r_begin = s_end - self.label_len \n","        r_end = r_begin + self.label_len + self.pred_len\n","\n","        seq_x = self.data_x[s_begin:s_end]\n","        if self.inverse:\n","            seq_y = np.concatenate([self.data_x[r_begin:r_begin+self.label_len], self.data_y[r_begin+self.label_len:r_end]], 0)\n","        else:\n","            seq_y = self.data_y[r_begin:r_end]\n","        seq_x_mark = self.data_stamp[s_begin:s_end]\n","        seq_y_mark = self.data_stamp[r_begin:r_end]\n","\n","        return seq_x, seq_y, seq_x_mark, seq_y_mark\n","    \n","    def __len__(self):\n","        return len(self.data_x) - self.seq_len- self.pred_len + 1\n","\n","    def inverse_transform(self, data):\n","        return self.scaler.inverse_transform(data)"],"metadata":{"id":"NfRWuZ89z-rA","executionInfo":{"status":"ok","timestamp":1670824375458,"user_tz":420,"elapsed":15,"user":{"displayName":"Jiwei Yao","userId":"13030184443101343713"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class TokenEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(TokenEmbedding, self).__init__()\n","        padding = 1 if torch.__version__>='1.5.0' else 2\n","        self.tokenConv = nn.Conv1d(in_channels=c_in, out_channels=d_model, \n","                                    kernel_size=3, padding=padding, padding_mode='circular')\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv1d):\n","                nn.init.kaiming_normal_(m.weight,mode='fan_in',nonlinearity='leaky_relu')\n","\n","    def forward(self, x):\n","        x = self.tokenConv(x.permute(0, 2, 1)).transpose(1,2)\n","        return x\n","\n","class PositionalEmbedding(nn.Module):\n","    def __init__(self, d_model, max_len=5000):\n","        super(PositionalEmbedding, self).__init__()\n","        # Compute the positional encodings once in log space.\n","        pe = torch.zeros(max_len, d_model).float()\n","        pe.require_grad = False\n","\n","        position = torch.arange(0, max_len).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","\n","        pe = pe.unsqueeze(0)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        return self.pe[:, :x.size(1)]\n","\n","class FixedEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model):\n","        super(FixedEmbedding, self).__init__()\n","\n","        w = torch.zeros(c_in, d_model).float()\n","        w.require_grad = False\n","\n","        position = torch.arange(0, c_in).float().unsqueeze(1)\n","        div_term = (torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model)).exp()\n","\n","        w[:, 0::2] = torch.sin(position * div_term)\n","        w[:, 1::2] = torch.cos(position * div_term)\n","\n","        self.emb = nn.Embedding(c_in, d_model)\n","        self.emb.weight = nn.Parameter(w, requires_grad=False)\n","\n","    def forward(self, x):\n","        return self.emb(x).detach()\n","\n","class TemporalEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='fixed', freq='h'):\n","        super(TemporalEmbedding, self).__init__()\n","\n","        max_len = 300\n","\n","        self.minute_embed = FixedEmbedding(max_len, d_model)\n","    \n","    def forward(self, x):\n","        x = x.long()\n","        \n","        return self.minute_embed(x[:, :, 0])\n","\n","\n","class TimeFeatureEmbedding(nn.Module):\n","    def __init__(self, d_model, embed_type='timeF', freq='h'):\n","        super(TimeFeatureEmbedding, self).__init__()\n","\n","        freq_map = {'m':1}\n","        d_inp = freq_map[freq]\n","        self.embed = nn.Linear(d_inp, d_model)\n","    \n","    def forward(self, x):\n","        return self.embed(x)\n","\n","\n","class DataEmbedding(nn.Module):\n","    def __init__(self, c_in, d_model, embed_type='timeF', freq='h', dropout=0.1):\n","        super(DataEmbedding, self).__init__()\n","\n","        self.value_embedding = TokenEmbedding(c_in=c_in, d_model=d_model)\n","        self.position_embedding = PositionalEmbedding(d_model=d_model)\n","        self.temporal_embedding = TemporalEmbedding(d_model=d_model, embed_type=embed_type, freq=freq) if embed_type!='timeF' else TimeFeatureEmbedding(d_model=d_model, embed_type=embed_type, freq=freq)\n","\n","        self.dropout = nn.Dropout(p=dropout)\n","\n","    def forward(self, x, x_mark):\n","        x = self.value_embedding(x) + self.position_embedding(x) + self.temporal_embedding(x_mark)\n","        \n","        return self.dropout(x)"],"metadata":{"id":"3IzY0zX2Vyzm","executionInfo":{"status":"ok","timestamp":1670824375773,"user_tz":420,"elapsed":329,"user":{"displayName":"Jiwei Yao","userId":"13030184443101343713"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["data_set = Dataset_cont_min(df)\n","train_data_loader = DataLoader(data_set,  \n","                               batch_size=32,\n","                               shuffle=True,\n","                               num_workers=0,\n","                               drop_last=True)\n","\n","for i, (batch_x,batch_y,batch_x_mark,batch_y_mark) in enumerate(train_data_loader):\n","  break"],"metadata":{"id":"CJmS_aFSJfSj","executionInfo":{"status":"ok","timestamp":1670824383051,"user_tz":420,"elapsed":288,"user":{"displayName":"Jiwei Yao","userId":"13030184443101343713"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"13i3NbFK5Qnz"},"execution_count":null,"outputs":[]}]}